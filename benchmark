#! /usr/bin/env python3

import sys
import os
import copy

from multirun import *
import FWCore.ParameterSet.Config as cms


if __name__ == "__main__":
  if not 'CMSSW_BASE' in os.environ:
    # FIXME print a meaningful error message
    sys.exit(1)

  if len(sys.argv) == 1:
    # FIXME print a meaningful error message
    sys.exit(1)

  # TODO parse arguments and options from the command line
  options = {
    'verbose'             : False,
    'plumbing'            : False,
    'warmup'              : True,
    'events'              : 10300,
    'repeats'             : 3,
    'jobs'                : 2,
    'threads'             : None,                       # per job
    'streams'             : None,                       # per job
    'gpus_per_job'        : 1,                          # per job
    'allow_hyperthreading': True,                       # this has no effect if set_cpu_affinity is False
    'set_cpu_affinity'    : True,
    'set_gpu_affinity'    : True,
    'logdir'              : 'logs',                     # relative or absolute path, or None to disable storing the logs
    'tmpdir'              : None,                       # temporary directory, or None to use a system dependent default temporary directory
    'keep'                : [ 'resources.json' ],       # additional output files to be kept, along with the logs
  }

  run_io_benchmark = True                               # measure the throughput for reading the input data

  # print a system overview
  info()

  # check the available cpus
  cpus = get_cpu_info()
  if options['allow_hyperthreading']:
    count = sum(len(cpu.hardware_threads) for cpu in cpus.values())
  else:
    count = sum(len(cpu.physical_processors) for cpu in cpus.values())

  # autodetermine either the number of jobs ot the nuber of threads per job
  if options['threads'] is None and options['jobs'] is None:
    sys.stderr.write('%s: error: either the number of jobs ot the nuber of threads per job must be specified\n' % sys.argv[0])
  elif options['threads'] is None:
    options['threads'] = count // options['jobs']
  elif options['jobs'] is None:
    options['jobs'] = count // options['threads']

  # the number of streams defaults to the number of threads per job
  if options['streams'] is None:
    options['streams'] = options['threads']

  for config in sys.argv[1:]:
    process = parseProcess(config)

    if run_io_benchmark:
      # prepare a trimmed down configuration for benchmarking only reading the input data
      io_process = copy.deepcopy(process)
      io_process.hltGetRaw = cms.EDAnalyzer("HLTGetRaw", RawDataCollection = cms.InputTag("rawDataCollector"))
      io_process.path = cms.Path(io_process.hltGetRaw)
      io_process.schedule = cms.Schedule(io_process.path)
      if 'PrescaleService' in io_process.__dict__:
        del io_process.PrescaleService

      # benchmark reading the input data
      print('Benchmarking only I/O')
      io_options = dict(options, logdir = None, keep = [])
      multiCmsRun(io_process, **io_options)
      run_io_benchmark = False
      print()

    print('Benchmarking %s' % config)
    multiCmsRun(process, **options)
